{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41aa924",
   "metadata": {},
   "source": [
    "Version: 02.14.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779e006",
   "metadata": {},
   "source": [
    "# Lab 7.1: Implementing a Multilingual Solution\n",
    "\n",
    "In this lab, you will learn how to use three different AWS services to create a solution that translates an audio file into text in a different language.\n",
    "\n",
    "## Introducing the business scenario\n",
    "\n",
    "In this lab, you play the role of a machine learning (ML) developer working for a media company that translates videos between multiple languages.  \n",
    "\n",
    "## Lab steps\n",
    "\n",
    "To complete this lab, you will follow these steps:\n",
    "\n",
    "1. [Amazon Transcribe example](#1.-Amazon-Transcribe-example)\n",
    "2. [Amazon Translate example](#2.-Amazon-Translate-example)\n",
    "3. [Amazon Polly example](#3.-Amazon-Polly-example)\n",
    "4. [Challenge exercise](#4.-Challenge-exercise)\n",
    "\n",
    "## Submitting your work\n",
    "\n",
    "1. In the lab console, choose **Submit** to record your progress and when prompted, choose **Yes**.\n",
    "\n",
    "1. If the results don't display after a couple of minutes, return to the top of the lab instructions and choose **Grades**.\n",
    "\n",
    "    **Tip:** You can submit your work multiple times. After you change your work, choose **Submit** again. Your last submission is what will be recorded for this lab.\n",
    "\n",
    "1. To find detailed feedback on your work, choose **Details** followed by **View Submission Report**.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449adc3e",
   "metadata": {},
   "source": [
    "## 1. Amazon Transcribe example\n",
    "([Go to top](#Lab-7.1:-Implementing-a-Multilingual-Solution))\n",
    "\n",
    "In this section, you will use the AWS SDK for Python (boto3) client to call Amazon Transcribe and convert an audio file into text. After running the example, you can go to the [Amazon Transcribe](https://console.aws.amazon.com/transcribe/home?region=us-east-1) console to see the transcription.\n",
    "\n",
    "It will take a few minutes for the transcription to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a06f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import boto3\n",
    "from time import sleep\n",
    "\n",
    "bucket = 'c127808a3228854l7992558t1w524885792761-labbucket-tvfzpxlrxrs0'\n",
    "database_access_role_arn = 'arn:aws:iam::524885792761:role/service-role/c127808a3228854l7992558t1w-ComprehendDataAccessRole-A53pkFNZOj7Z'\n",
    "translate_access_role_arn = 'arn:aws:iam::524885792761:role/c127808a3228854l7992558t1w5248857-TranslateDemoRole-5qZAWheZwPQ2'\n",
    "\n",
    "\n",
    "transcribe_client = boto3.client(\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d661c62b",
   "metadata": {},
   "source": [
    "The test.wav sample file is located in the **/s3** folder. The file contains the audio phrase \"Test. Hello, hello, hello. This is a test. Test, test, test.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad42bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input parameters for job_name and job_uri\n",
    "media_input_uri = f's3://{bucket}/lab71/transcribe-sample/test.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cf229",
   "metadata": {},
   "source": [
    "First, create the transcription job with the test.wav file as the input. Note that you need to specify an output location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ef5eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the transcription job\n",
    "job_uuid = uuid.uuid1()\n",
    "transcribe_job_name = f\"transcribe-job-{job_uuid}\"\n",
    "transcribe_output_filename = 'transcribe_output.txt'\n",
    "\n",
    "response = transcribe_client.start_transcription_job(\n",
    "    TranscriptionJobName=transcribe_job_name,\n",
    "    Media={'MediaFileUri': media_input_uri},\n",
    "    MediaFormat='wav',\n",
    "    LanguageCode='en-US',\n",
    "    OutputBucketName=bucket,\n",
    "    OutputKey=transcribe_output_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cca16",
   "metadata": {},
   "source": [
    "Wait until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf38347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".COMPLETED\n"
     ]
    }
   ],
   "source": [
    "job=None\n",
    "while True:\n",
    "    job = transcribe_client.get_transcription_job(TranscriptionJobName = transcribe_job_name)\n",
    "    if job['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED','FAILED']:\n",
    "        break\n",
    "    print('.', end='')\n",
    "    sleep(20)\n",
    "        \n",
    "print(job['TranscriptionJob']['TranscriptionJobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563671c6",
   "metadata": {},
   "source": [
    "If the output from the previous cell is *COMPLETED*, then proceed. Otherwise, correct the error and retry the previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05095a",
   "metadata": {},
   "source": [
    "To retrieve the output file, use the results from the `get_transcription_job` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a8dec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.us-east-1.amazonaws.com/c127808a3228854l7992558t1w524885792761-labbucket-tvfzpxlrxrs0/transcribe_output.txt\n"
     ]
    }
   ],
   "source": [
    "transcription_file = job['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "print(transcription_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c0ee6",
   "metadata": {},
   "source": [
    "To download the file from Amazon Simple Storage Service (Amazon S3), use the S3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382d374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "with open(transcribe_output_filename, 'wb') as f:\n",
    "    s3_client.download_fileobj(bucket, transcribe_output_filename, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12a68b9",
   "metadata": {},
   "source": [
    "Open the file and read the contents into a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbb925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(transcribe_output_filename) as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b216de3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobName': 'transcribe-job-9566f9fc-8c49-11ef-bc38-0ef582ee11df',\n",
       " 'accountId': '524885792761',\n",
       " 'status': 'COMPLETED',\n",
       " 'results': {'transcripts': [{'transcript': 'Test. Hello. Hello. Hello. This is a test test test test.'}],\n",
       "  'items': [{'id': 0,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.996', 'content': 'Test'}],\n",
       "    'start_time': '0.009',\n",
       "    'end_time': '0.56'},\n",
       "   {'id': 1,\n",
       "    'type': 'punctuation',\n",
       "    'alternatives': [{'confidence': '0.0', 'content': '.'}]},\n",
       "   {'id': 2,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.997', 'content': 'Hello'}],\n",
       "    'start_time': '0.66',\n",
       "    'end_time': '1.19'},\n",
       "   {'id': 3,\n",
       "    'type': 'punctuation',\n",
       "    'alternatives': [{'confidence': '0.0', 'content': '.'}]},\n",
       "   {'id': 4,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.996', 'content': 'Hello'}],\n",
       "    'start_time': '1.2',\n",
       "    'end_time': '1.7'},\n",
       "   {'id': 5,\n",
       "    'type': 'punctuation',\n",
       "    'alternatives': [{'confidence': '0.0', 'content': '.'}]},\n",
       "   {'id': 6,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.997', 'content': 'Hello'}],\n",
       "    'start_time': '1.71',\n",
       "    'end_time': '2.49'},\n",
       "   {'id': 7,\n",
       "    'type': 'punctuation',\n",
       "    'alternatives': [{'confidence': '0.0', 'content': '.'}]},\n",
       "   {'id': 8,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.999', 'content': 'This'}],\n",
       "    'start_time': '2.73',\n",
       "    'end_time': '3.47'},\n",
       "   {'id': 9,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.999', 'content': 'is'}],\n",
       "    'start_time': '3.48',\n",
       "    'end_time': '3.73'},\n",
       "   {'id': 10,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.997', 'content': 'a'}],\n",
       "    'start_time': '3.74',\n",
       "    'end_time': '3.75'},\n",
       "   {'id': 11,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.999', 'content': 'test'}],\n",
       "    'start_time': '3.759',\n",
       "    'end_time': '4.67'},\n",
       "   {'id': 12,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.996', 'content': 'test'}],\n",
       "    'start_time': '4.679',\n",
       "    'end_time': '5.36'},\n",
       "   {'id': 13,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.997', 'content': 'test'}],\n",
       "    'start_time': '5.369',\n",
       "    'end_time': '5.679'},\n",
       "   {'id': 14,\n",
       "    'type': 'pronunciation',\n",
       "    'alternatives': [{'confidence': '0.997', 'content': 'test'}],\n",
       "    'start_time': '5.69',\n",
       "    'end_time': '6.15'},\n",
       "   {'id': 15,\n",
       "    'type': 'punctuation',\n",
       "    'alternatives': [{'confidence': '0.0', 'content': '.'}]}],\n",
       "  'audio_segments': [{'id': 0,\n",
       "    'transcript': 'Test. Hello. Hello. Hello. This is a test test test test.',\n",
       "    'start_time': '0.0',\n",
       "    'end_time': '6.309',\n",
       "    'items': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ec886",
   "metadata": {},
   "source": [
    "To get the actual transcription, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecbeb416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test. Hello. Hello. Hello. This is a test test test test.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['results']['transcripts'][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf88529",
   "metadata": {},
   "source": [
    "## 2. Amazon Translate example\n",
    "\n",
    "([Go to top](#Lab-7.1:-Implementing-a-Multilingual-Solution))\n",
    "\n",
    "In this section, you will use the AWS SDK for Python (boto3) client to call Amazon Translate and convert a text file from English to Spanish. After running the example, you can go to the [Amazon Translate](https://console.aws.amazon.com/translate/home?region=us-east-1#batch-translation) console to see the translation.\n",
    "\n",
    "The translation and details about the job are located in the **Batch translation** section. The text file containing the translation will be in your S3 bucket. The bucket will also have a **details** folder that contains a JSON file with details about the translation, such as the source and target languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac454ee",
   "metadata": {},
   "source": [
    "First, create the translation job. The input and output locations are required.\n",
    "\n",
    "Note that Amazon Translate can translate the same text into multiple target languages. In this example, you will use Spanish, for which the language code is `es`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "181d7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "translate_client = boto3.client(service_name='translate')\n",
    "\n",
    "input_data = f's3://{bucket}/lab71/translate-sample'\n",
    "output_data = f's3://{bucket}'\n",
    "\n",
    "job_uuid = uuid.uuid1()\n",
    "translate_job_name = f\"translate-job-{job_uuid}\"\n",
    "translate_job_submission = translate_client.start_text_translation_job(\n",
    "    JobName=translate_job_name,\n",
    "    InputDataConfig={'S3Uri': input_data, 'ContentType':'text/plain'},\n",
    "    OutputDataConfig={'S3Uri': output_data},\n",
    "    DataAccessRoleArn=translate_access_role_arn,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCodes=['es']\n",
    ")\n",
    "translate_job_id = translate_job_submission['JobId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669489b",
   "metadata": {},
   "source": [
    "Use the job ID from the previous cell to get the status. Wait for the job to complete.\n",
    "\n",
    "Note that the job will take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbb9761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................COMPLETED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    translate_job = translate_client.describe_text_translation_job(JobId=translate_job_id)\n",
    "    if translate_job['TextTranslationJobProperties']['JobStatus'] in ['COMPLETED','FAILED']:\n",
    "        break\n",
    "    sleep(20)\n",
    "    print('.', end='')\n",
    "\n",
    "print(translate_job['TextTranslationJobProperties']['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127abff3",
   "metadata": {},
   "source": [
    "If the output from the previous cell is *COMPLETED*, then proceed. Otherwise, correct the error and retry the previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dffee",
   "metadata": {},
   "source": [
    "The format of the output folder is created from the account number and job ID. The following cell creates a path with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344a42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "translate_output_path = f'{account_id}-TranslateText-{translate_job_id}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162ad1c",
   "metadata": {},
   "source": [
    "Amazon Translate outputs several files. You are interested in the .txt file, which contains the results from the translation. The following cell will download the .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a17d04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".test.txt\n"
     ]
    }
   ],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "my_bucket = s3_resource.Bucket(bucket)\n",
    "\n",
    "for my_bucket_object in my_bucket.objects.filter(Prefix=translate_output_path):\n",
    "    file=my_bucket_object.key\n",
    "    if file.endswith('txt'):\n",
    "        file = file.lstrip(translate_output_path)\n",
    "        file = file.lstrip('/')\n",
    "        print(file)\n",
    "        with open(file, 'wb') as f:\n",
    "            s3_client.download_fileobj(bucket, my_bucket_object.key, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389c6ff",
   "metadata": {},
   "source": [
    "## 3. Amazon Polly example\n",
    "\n",
    "([Go to top](#Lab-7.1:-Implementing-a-Multilingual-Solution))\n",
    "\n",
    "In this section, you will use the AWS SDK for Python (boto3) client to call Amazon Polly and create a vocalization of a text file in Spanish.\n",
    "\n",
    "After you run the cell, open your S3 bucket to see the output. The output is an .mp3 file with a long string as the file name. You can open the file and hear the Lucia voice saying \"Prueba de prueba, este es una prueba.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31324245",
   "metadata": {},
   "outputs": [],
   "source": [
    "polly_client = boto3.client('polly')\n",
    "\n",
    "itemname = 'lab71/polly-sample/es.test.txt'\n",
    "obj = s3_resource.Object(bucket, itemname )\n",
    "body = obj.get()['Body'].read().decode('utf-8')\n",
    "\n",
    "response = polly_client.start_speech_synthesis_task(\n",
    "    Engine='standard',\n",
    "    OutputFormat='mp3',\n",
    "    OutputS3BucketName=bucket,\n",
    "    Text=body,\n",
    "    VoiceId='Lucia'\n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e2508",
   "metadata": {},
   "source": [
    "Extract the task ID from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb83441",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = response['SynthesisTask']['TaskId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8155d3",
   "metadata": {},
   "source": [
    "Use this task ID to check whether the job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d965684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".completed\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    polly_job = polly_client.get_speech_synthesis_task(TaskId=task_id)\n",
    "    if polly_job['SynthesisTask']['TaskStatus'] in ['completed','failed']:\n",
    "        break\n",
    "    sleep(20)\n",
    "    print('.', end='')\n",
    "\n",
    "print(polly_job['SynthesisTask']['TaskStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a55b2",
   "metadata": {},
   "source": [
    "If the output from the previous cell is *completed*, then proceed. Otherwise, correct the error and retry the previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8456126",
   "metadata": {},
   "source": [
    "To download the results, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df967f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "polly_output_filename = f'{task_id}.mp3'\n",
    "with open(polly_output_filename, 'wb') as f:\n",
    "    s3_client.download_fileobj(bucket, polly_output_filename, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9f4f5",
   "metadata": {},
   "source": [
    "## 4. Challenge exercise\n",
    "\n",
    "([Go to top](#Lab-7.1:-Implementing-a-Multilingual-Solution))\n",
    "    \n",
    "Your challenge is to create a translated audio file from a video that has an English audio channel. You can use the code from the previous three examples as a template for your solution.\n",
    "\n",
    "The video for the challenge is in your S3 bucket in the `lab71/challenge` folder. The video file is named sample.mp4. This file is also available in the `/s3` folder in this notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0638910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription completed: https://s3.us-east-1.amazonaws.com/c127808a3228854l7992558t1w524885792761-labbucket-tvfzpxlrxrs0/challenge_transcription.txt\n",
      "Transcribed Text: Hi and welcome to Amazon Academy and Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to learn more about machine learning. After completing this module, you should be able to identify course prerequisites and objectives indicate the role of the data scientist in business and identify resources for further learning. We're now going to look at the prerequisites for taking this course. Before you take this course, we recommend that you first complete Aws Academy cloud foundations. You should also have some general technical knowledge of it including foundational computer literacy skills like basic computer concepts, email file management and a good understanding of the internet. We also recommend that you have intermediate skills with Python programming and a general knowledge of applied statistics. Finally, general business knowledge is important for this course. This includes insight into how information technology is used in business. It's also important to have business related skill sets such as communication skills, leadership skills, and an orientation towards customer service. In this course, you'll be introduced to the key concepts of machine learning, its tools and its uses you'll also be introduced to and work with some of the AWS services for machine learning. You'll learn how to recognize how machine learning and deep learning are part of artificial intelligence. Describe artificial intelligence and machine learning terminology. Identify how machine learning can be used to solve a business problem. Describe the machine learning process. List the tools available to data scientists and identify when to use machine learning instead of traditional software development methods. As part of this course, you'll also learn how to implement a machine learning pipeline. This includes how to formulate a problem from a business request, obtain and secure data for machine learning, build a Jupiter notebook by using Amazon Sage maker outline the process for evaluating data. Explain why data needs to be preprocess and use open source tools to examine and preprocess data. You will also use Amazon Sage Maker to train and host a machine learning model, use cross validation to test the performance of a machine learning model. Use a hosted model for inference, create an Amazon Sage maker hyper parameter tuning job to optimize a model's effectiveness. And finally how to use managed Amazon machine learning services to solve specific machine learning problems in forecasting computer vision and natural language processing. We'll now review the course outline to achieve the course objectives. You'll complete the following modules to start in module two, you'll get an introduction to machine learning in module three. You'll learn how to implement a machine learning pipeline with Amazon Sage maker modules 45 and six describe how to apply managed Amazon machine learning services for problems in forecasting computer vision and natural language processing. Finally, module seven is a summary of the course. It also includes an overview of steps you can take to work towards the AWS certified machine learning specialty. The next five slides provide more detail about the subtopics covered in each module. The purpose of module two is to introduce you to major concepts for understanding machine learning. Section one describes the overall field of machine learning and how machine learning relates to artificial intelligence and deep learning. In section two, you'll learn about some of the most common business problems you can solve with machine learning. Section three describes the general workflow for solving machine learning problems. You'll also learn some of the more common machine learning terms. In section four, you'll review some of the commonly used tools by machine learning professionals. And lastly in section five, you'll get an overview of some of the common challenges you'll face when working with machine learning problems. In module three, you'll get an introduction to Amazon Sage Maker and how you can use it to implement a machine learning pipeline. The module focuses on the application of machine learning to solve problems with several public domain data sets. As examples of the machine learning pipeline. Section one introduces you to defining business problems and the data sets we will use during this module, section two through eight, describe the phases of the machine learning pipeline by using computer vision as an example application. In section two, you'll learn how to collect and secure data. Section three describes different techniques for evaluating data. In section four, you'll learn about the process of feature engineering. Section five described the steps he'll take to train a model with stage maker. In section six, you'll get an overview of the options in Sage maker for hosting and using a model. Finally, section seven and eight cover how to evaluate and tune your model with Sage Maker. In this module, you'll be introduced to using machine learning to create forecasts based on a time series data. In section one, you'll be introduced to forecasting in some of its common applications. Section two outlines some of the pitfalls of using time series data to make forecasts. Finally, in section three, you'll get an overview of how to use Amazon forecast in this module, you'll learn about using machine learning for computer vision. Section one describes the general problems you can solve with computer vision. In section two, you'll learn about the process for analyzing images and videos. And in section three, you'll learn the steps you'll need to take to prepare data sets for computer vision. In this module, you'll be introduced to natural language processing with machine learning. In section one, you'll learn about the general set of problems you can solve with natural language processing section two reviews. Some of the managed Amazon machine learning services you can use to address natural language processing problems. These services include Amazon transcribe, Amazon translate, Amazon, Lex Amazon comprehend and Amazon poly module seven is the final module of the course. In this module, you'll review what you've learned throughout this course. You'll also be introduced to the next steps you should take. If you want to achieve the Aws Certified Machine learning specialty section, one of this module summarizes the topics you've covered in this course. In section two, you'll learn more about the Aws documentation. You'll also review two common frameworks for applying Aws services. And finally, section three describes the steps you should take. If you want to continue working towards the Aws Certified machine learning specialty in this section, you'll learn about some of the more common job roles for machine learning professionals. If you're interested in a data scientist role, focus on developing analytical statistical and programming skills. As a data scientist, you'll use those skills to collect analyze and interpret large data sets. Some universities now offer degrees in data science, but data scientists often have degrees in related fields like statistics, math, computer science or economics. As a data scientist, you'll need technical competencies in statistics, machine learning, programming languages and data analytics. If you'd like to have a career as a machine learning engineer, the skills you'll need will be similar to a data scientist, skill set like data scientists, machine learning engineers also require technical competencies in statistics and machine learning. However, you'll focus more on programming skills and software architecture than analysis and interpretation. As a machine learning engineer, you'll apply those programming and architecture skills to design and develop machine learning systems. Machine learning engineers often have previous experience with software development and they rely more heavily on programming and software engineering than other machine learning roles. You might also be interested in a career in science where you can apply machine learning technology to your field. Machine learning is having an impact in everything from astronomy to zoology. So there are many different paths open to you. As an applied science researcher, your primary focus will be on the type of science you're working on. You'll need some of the same skills as a data scientist, but you'll also need to know how to apply those skills to your chosen domain. Thus, applied science rules also require technical competencies in statistics and machine learning. Many software developers are now integrating machine learning into their applications. If you're interested in a career as a software developer, you should also include machine learning technology in your studies. As a machine learning developer, your primary focus will be software development skills, but you'll also need some of the same skills as a data scientist. So make sure you take coursework in statistics and applied mathematics. And here's a final note for this module, we recommend reviewing your student guide in your student guide. You'll find links to documentation and other resources you'll use throughout the course. That's it for this introduction. Thanks for watching. We'll see you in the next video.\n",
      "Translated Text: Hola, le damos la bienvenida a Amazon Academy y Machine Learning Foundations. En este módulo conocerá los objetivos del curso, las distintas funciones laborales en el campo del aprendizaje automático y dónde puede obtener más información sobre el aprendizaje automático. Tras completar este módulo, podrás identificar los requisitos previos y los objetivos del curso, determinar la función del científico de datos en la empresa e identificar los recursos para seguir aprendiendo. Ahora vamos a ver los requisitos previos para cursar este curso. Antes de realizar este curso, le recomendamos que primero complete los fundamentos de la nube de Aws Academy. También debe tener algunos conocimientos técnicos generales al respecto, incluidos los conocimientos básicos de informática, como los conceptos básicos de informática, la administración de archivos de correo electrónico y un buen conocimiento de Internet. También le recomendamos que tenga habilidades intermedias con la programación en Python y un conocimiento general de la estadística aplicada. Por último, los conocimientos empresariales generales son importantes para este curso. Esto incluye información sobre cómo se utiliza la tecnología de la información en los negocios. También es importante contar con conjuntos de habilidades relacionadas con la empresa, como habilidades de comunicación, habilidades de liderazgo y una orientación hacia el servicio al cliente. En este curso, conocerá los conceptos clave del aprendizaje automático, sus herramientas y sus usos. También conocerá algunos de los servicios de AWS para el aprendizaje automático y trabajará con ellos. Aprenderá a reconocer cómo el aprendizaje automático y el aprendizaje profundo forman parte de la inteligencia artificial. Describa la terminología de inteligencia artificial y aprendizaje automático. Identifique cómo se puede utilizar el aprendizaje automático para resolver un problema empresarial. Describa el proceso de aprendizaje automático. Enumere las herramientas disponibles para los científicos de datos e identifique cuándo usar el aprendizaje automático en lugar de los métodos tradicionales de desarrollo de software. Como parte de este curso, también aprenderás a implementar un proceso de aprendizaje automático. Esto incluye cómo formular un problema a partir de una solicitud empresarial, obtener y proteger datos para el aprendizaje automático, crear un cuaderno Jupiter con Amazon Sage Maker y describir el proceso de evaluación de datos. Explique por qué es necesario preprocesar los datos y utilice herramientas de código abierto para examinar y preprocesar los datos. También utilizará Amazon Sage Maker para entrenar y alojar un modelo de aprendizaje automático, y utilizará la validación cruzada para probar el rendimiento de un modelo de aprendizaje automático. Utilice un modelo alojado para hacer inferencias y cree un trabajo de ajuste de hiperparámetros en Amazon Sage Maker para optimizar la eficacia del modelo. Y, por último, cómo utilizar los servicios gestionados de aprendizaje automático de Amazon para resolver problemas específicos de aprendizaje automático relacionados con la previsión de la visión artificial y el procesamiento del lenguaje natural. Ahora revisaremos el esquema del curso para lograr los objetivos del curso. Completará los siguientes módulos para comenzar en el módulo dos y recibirá una introducción al aprendizaje automático en el módulo tres. Aprenderás a implementar un proceso de aprendizaje automático con Amazon Sage. Los módulos 45 y seis de Amazon Sage Maker describen cómo aplicar los servicios gestionados de aprendizaje automático de Amazon para problemas relacionados con la previsión, la visión artificial y el procesamiento del lenguaje natural. Por último, el módulo siete es un resumen del curso. También incluye una descripción general de las medidas que puede tomar para convertirse en una especialidad de aprendizaje automático certificada por AWS. Las siguientes cinco diapositivas proporcionan más detalles sobre los subtemas tratados en cada módulo. El propósito del módulo dos es presentarle los conceptos principales para entender el aprendizaje automático. La primera sección describe el campo general del aprendizaje automático y cómo el aprendizaje automático se relaciona con la inteligencia artificial y el aprendizaje profundo. En la sección dos, conocerá algunos de los problemas empresariales más comunes que puede resolver con el aprendizaje automático. La sección tres describe el flujo de trabajo general para resolver problemas de aprendizaje automático. También aprenderá algunos de los términos más comunes de aprendizaje automático. En la sección cuatro, revisará algunas de las herramientas más utilizadas por los profesionales del aprendizaje automático. Por último, en la sección cinco, obtendrás una descripción general de algunos de los desafíos comunes a los que te enfrentarás cuando trabajes con problemas de aprendizaje automático. En el módulo tres, obtendrá una introducción a Amazon Sage Maker y a cómo puede usarlo para implementar un proceso de aprendizaje automático. El módulo se centra en la aplicación del aprendizaje automático para resolver problemas con varios conjuntos de datos de dominio público. Como ejemplos del proceso de aprendizaje automático. En la primera sección se explica cómo definir los problemas empresariales y los conjuntos de datos que utilizaremos durante este módulo, de la segunda a la octava, describen las fases del proceso de aprendizaje automático utilizando la visión artificial como aplicación de ejemplo. En la segunda sección, aprenderá a recopilar y proteger los datos. La sección tres describe diferentes técnicas para evaluar los datos. En la sección cuatro, aprenderás sobre el proceso de ingeniería de funciones. En la sección cinco se describen los pasos que tomará para entrenar a un modelo con Stage Maker. En la sección seis, obtendrás una descripción general de las opciones de Sage Maker para alojar y usar un modelo. Por último, las secciones siete y ocho explican cómo evaluar y ajustar tu modelo con Sage Maker. En este módulo, conocerás el uso del aprendizaje automático para crear pronósticos basados en datos de series temporales. En la sección uno, se le presentará la previsión en algunas de sus aplicaciones más comunes. La segunda sección describe algunos de los inconvenientes de usar datos de series temporales para hacer pronósticos. Por último, en la sección tres, obtendrás una descripción general de cómo usar las previsiones de Amazon. En este módulo, aprenderás a usar el aprendizaje automático para la visión artificial. La primera sección describe los problemas generales que se pueden resolver con la visión artificial. En la sección dos, aprenderás sobre el proceso de análisis de imágenes y vídeos. Y en la sección tres, aprenderá los pasos que deberá seguir para preparar los conjuntos de datos para la visión artificial. En este módulo, conocerás el procesamiento del lenguaje natural con el aprendizaje automático. En la sección uno, conocerás el conjunto general de problemas que puedes resolver con el procesamiento del lenguaje natural, en las reseñas de la segunda sección. Algunos de los servicios gestionados de aprendizaje automático de Amazon puedes usar para solucionar problemas de procesamiento del lenguaje natural. Estos servicios incluyen Amazon transcribe, Amazon translate, Amazon, Lex, Amazon comprehenend y Amazon Poly, el módulo siete es el último módulo del curso. En este módulo, revisará lo que ha aprendido a lo largo del curso. También se le presentarán los siguientes pasos que debe seguir. Si desea obtener la sección especializada en aprendizaje automático certificada por Aws, en uno de estos módulos se resumen los temas que ha tratado en este curso. En la sección dos, obtendrá más información sobre la documentación de Aws. También revisará dos marcos comunes para aplicar los servicios de Aws. Y, por último, en la sección tres se describen los pasos que debe seguir. Si desea seguir trabajando en la especialidad de aprendizaje automático certificada por AWS, en esta sección encontrará información sobre algunas de las funciones laborales más habituales de los profesionales del aprendizaje automático. Si está interesado en ocupar un puesto de científico de datos, céntrese en desarrollar habilidades analíticas, estadísticas y de programación. Como científico de datos, utilizarás esas habilidades para recopilar, analizar e interpretar grandes conjuntos de datos. Algunas universidades ahora ofrecen títulos en ciencia de datos, pero los científicos de datos suelen tener títulos en campos relacionados, como estadística, matemáticas, informática o economía. Como científico de datos, necesitarás competencias técnicas en estadística, aprendizaje automático, lenguajes de programación y análisis de datos. Si quieres tener una carrera como ingeniero de aprendizaje automático, necesitarás habilidades similares a las de un científico de datos, un conjunto de habilidades como las de un científico de datos. Los ingenieros de aprendizaje automático también requieren competencias técnicas en estadística y aprendizaje automático. Sin embargo, te centrarás más en las habilidades de programación y la arquitectura de software que en el análisis y la interpretación. Como ingeniero de aprendizaje automático, aplicará esas habilidades de programación y arquitectura para diseñar y desarrollar sistemas de aprendizaje automático. Los ingenieros de aprendizaje automático suelen tener experiencia previa en el desarrollo de software y dependen más de la programación y la ingeniería de software que de otras funciones de aprendizaje automático. También te puede interesar una carrera científica en la que puedas aplicar la tecnología de aprendizaje automático a tu campo. El aprendizaje automático está teniendo un impacto en todo, desde la astronomía hasta la zoología. Por lo tanto, hay muchos caminos diferentes abiertos para ti. Como investigador de ciencias aplicadas, tu enfoque principal será el tipo de ciencia en la que estás trabajando. Necesitarás algunas de las mismas habilidades que un científico de datos, pero también necesitarás saber cómo aplicar esas habilidades al dominio que hayas elegido. Por lo tanto, las reglas de la ciencia aplicada también requieren competencias técnicas en estadística y aprendizaje automático. Muchos desarrolladores de software ahora están integrando el aprendizaje automático en sus aplicaciones. Si está interesado en una carrera como desarrollador de software, también debería incluir la tecnología de aprendizaje automático en sus estudios. Como desarrollador de aprendizaje automático, tu enfoque principal serán las habilidades de desarrollo de software, pero también necesitarás algunas de las mismas habilidades que un científico de datos. Así que asegúrate de tomar cursos de estadística y matemáticas aplicadas. Y he aquí una nota final para este módulo. Te recomendamos revisar tu guía estudiantil en tu guía estudiantil. Encontrarás enlaces a la documentación y otros recursos que utilizarás a lo largo del curso. Eso es todo por lo que respecta a esta introducción. Gracias por mirar. Nos vemos en el siguiente vídeo.\n",
      "Polly synthesis completed: b53cc6f3-bb69-4306-8319-105f337556a7\n",
      "Translated audio saved as: b53cc6f3-bb69-4306-8319-105f337556a7.mp3\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import json\n",
    "import boto3\n",
    "from time import sleep\n",
    "\n",
    "# Initialize AWS clients\n",
    "transcribe_client = boto3.client(\"transcribe\")\n",
    "translate_client = boto3.client(\"translate\")\n",
    "polly_client = boto3.client(\"polly\")\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "# Bucket and roles\n",
    "bucket = 'c127808a3228854l7992558t1w524885792761-labbucket-tvfzpxlrxrs0'\n",
    "translate_access_role_arn = 'arn:aws:iam::524885792761:role/c127808a3228854l7992558t1w5248857-TranslateDemoRole-5qZAWheZwPQ2'\n",
    "\n",
    "# 1. Transcribe the audio from the video (sample.mp4)\n",
    "media_input_uri = f's3://{bucket}/lab71/challenge/sample.mp4'\n",
    "transcribe_job_name = f\"transcribe-challenge-{uuid.uuid1()}\"\n",
    "output_key = 'challenge_transcription.txt'\n",
    "\n",
    "response = transcribe_client.start_transcription_job(\n",
    "    TranscriptionJobName=transcribe_job_name,\n",
    "    Media={'MediaFileUri': media_input_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US',\n",
    "    OutputBucketName=bucket,\n",
    "    OutputKey=output_key\n",
    ")\n",
    "\n",
    "# Wait for the transcription to complete\n",
    "while True:\n",
    "    job = transcribe_client.get_transcription_job(TranscriptionJobName=transcribe_job_name)\n",
    "    if job['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    sleep(20)\n",
    "\n",
    "if job['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
    "    transcription_file = job['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "    print(f\"Transcription completed: {transcription_file}\")\n",
    "\n",
    "# Download the transcription file\n",
    "with open(output_key, 'wb') as f:\n",
    "    s3_client.download_fileobj(bucket, output_key, f)\n",
    "\n",
    "# Read the transcription text\n",
    "with open(output_key) as f:\n",
    "    data = json.load(f)\n",
    "transcribed_text = data['results']['transcripts'][0]['transcript']\n",
    "print(f\"Transcribed Text: {transcribed_text}\")\n",
    "\n",
    "# 2. Translate the transcribed text to Spanish\n",
    "translation = translate_client.translate_text(\n",
    "    Text=transcribed_text,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='es'\n",
    ")\n",
    "translated_text = translation['TranslatedText']\n",
    "print(f\"Translated Text: {translated_text}\")\n",
    "\n",
    "# 3. Convert the translated text into speech using Amazon Polly\n",
    "response = polly_client.start_speech_synthesis_task(\n",
    "    Engine='standard',\n",
    "    OutputFormat='mp3',\n",
    "    OutputS3BucketName=bucket,\n",
    "    Text=translated_text,\n",
    "    VoiceId='Lucia'\n",
    ")\n",
    "\n",
    "# Wait for the Polly job to complete\n",
    "task_id = response['SynthesisTask']['TaskId']\n",
    "while True:\n",
    "    polly_job = polly_client.get_speech_synthesis_task(TaskId=task_id)\n",
    "    if polly_job['SynthesisTask']['TaskStatus'] in ['completed', 'failed']:\n",
    "        break\n",
    "    sleep(20)\n",
    "\n",
    "if polly_job['SynthesisTask']['TaskStatus'] == 'completed':\n",
    "    print(f\"Polly synthesis completed: {task_id}\")\n",
    "\n",
    "# 4. Download the MP3 audio file\n",
    "polly_output_filename = f\"{task_id}.mp3\"\n",
    "with open(polly_output_filename, 'wb') as f:\n",
    "    s3_client.download_fileobj(bucket, polly_output_filename, f)\n",
    "\n",
    "print(f\"Translated audio saved as: {polly_output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f73b8d",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this lab, and you can now end the lab by following the lab guide instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023b742",
   "metadata": {},
   "source": [
    "*©2023 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. All trademarks are the property of their owners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
